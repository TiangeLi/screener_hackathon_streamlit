{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "limit_lines = 50   # API costs, so limit to 50 entries for now\n",
    "\n",
    "dataset = pd.read_csv(\"final_inclusion_in_SR.csv\")[:limit_lines]\n",
    "articles = [f\"{entry[\"Title\"]}:\\n\\n{entry[\"Abstract\"]}\" for _, entry in dataset.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_question = \"What is the association between exposure to radiotherapy for prostate cancer and incidence/risk of second malignancy / second primary cancers?\"\n",
    "\n",
    "exclusion_criteria = \"non-clinical studies, editorials, review articles, case reports, conference abstracts, basic science papers, unclear comparator group, metastatic tumors, non-standard treatment for prostate cancer (such as cryotherapy), articles not dealing with radiation induced malignancy\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from typing import TypedDict, Annotated, Literal, Optional\n",
    "\n",
    "class ExtractedStudyData(TypedDict):\n",
    "    data_sources: Annotated[Optional[str], ..., \"for each data collected, summarize what/where/when/who it was collected from\"]\n",
    "    study_design: Annotated[Optional[Literal[\"Cohort\", \"Case-control\", \"Cross-sectional\", \"\", \"Experimental\", \"Other\"]], ..., \"based on the data source, what is the type of study conducted?\"]\n",
    "    study_accrural_periods: Optional[str]\n",
    "    sample_size: Optional[int]\n",
    "    exposures: Annotated[Optional[str], ..., \"exposures, with the sources of the exposures if available\"]\n",
    "    exposure_ascertainment: Annotated[Optional[str], ..., \"i.e., how was the exposure measured / what was the data source?\"]\n",
    "    outcomes: Optional[str]\n",
    "    outcome_ascertainment: Annotated[Optional[str], ..., \"i.e., how was the outcome measured / what was the data source?\"]\n",
    "    all_results: Annotated[Optional[str], ..., \"results verbatim, including all stats and metrics where available\"]\n",
    "    conclusions: Optional[str]\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.2)\n",
    "\n",
    "template = \\\n",
    "\"\"\"Please very carefully extract the following data from the article. \n",
    "Be very meticulous and specific for each category. If information is not available for a category, please leave it blank.\n",
    "\n",
    "Please extract data as it relates to this question of interest:\n",
    "{screening_question}\n",
    "\n",
    "<article>\n",
    "{article}\n",
    "</article>\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate([\n",
    "    (\"system\", template),\n",
    "])\n",
    "\n",
    "chain = prompt | llm.with_structured_output(ExtractedStudyData, method=\"json_schema\", strict=True)\n",
    "\n",
    "extracted = chain.batch([{\n",
    "    \"article\": e,\n",
    "    \"screening_question\": screening_question\n",
    "} for e in articles], {\"max_concurrency\": 10})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in extracted:\n",
    "    for k, v in e.items():\n",
    "        print(k, v)\n",
    "    print(\"\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "screening_prompt = \\\n",
    "\"\"\"Given the following article information, please decide if it should be included in the analysis, based on the screening question and exclusion criteria.\n",
    "\n",
    "<article>\n",
    "{article}\n",
    "</article>\n",
    "\n",
    "<screening_question>\n",
    "{screening_question}\n",
    "</screening_question>\n",
    "\n",
    "<exclusion_criteria>\n",
    "{exclusion_criteria}\n",
    "</exclusion_criteria>\"\"\"\n",
    "\n",
    "sr_prompt = ChatPromptTemplate([\n",
    "    (\"system\", screening_prompt),\n",
    "])\n",
    "\n",
    "class Inclusion(TypedDict):\n",
    "    include: bool\n",
    "    reason_if_excluded: Optional[str]\n",
    "\n",
    "sr_chain = sr_prompt | llm.with_structured_output(Inclusion, method=\"json_schema\", strict=True)\n",
    "\n",
    "result = sr_chain.batch([{\n",
    "    \"article\": e,\n",
    "    \"screening_question\": screening_question,\n",
    "    \"exclusion_criteria\": exclusion_criteria\n",
    "} for e in extracted], {\"max_concurrency\": 10})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in result:\n",
    "    for k, v in r.items():\n",
    "        print(k, v)\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
